{"cells":[{"source":"# Data Manipulation with pandas\nRun the hidden code cell below to import the data used in this course.","metadata":{"id":"bA5ajAmk7XH6"},"id":"prostate-arizona","cell_type":"markdown"},{"source":"# Import the course packages\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Import the four datasets\navocado = pd.read_csv(\"datasets/avocado.csv\")\nhomelessness = pd.read_csv(\"datasets/homelessness.csv\")\ntemperatures = pd.read_csv(\"datasets/temperatures.csv\")\nwalmart = pd.read_csv(\"datasets/walmart.csv\")","metadata":{"scrolled":true,"collapsed":false,"jupyter":{"outputs_hidden":false,"source_hidden":false}},"id":"2e25fdd8-4d84-45bc-80f0-949917e00a17","cell_type":"code","execution_count":null,"outputs":[]},{"source":"## Take Notes\n.head() returns the first few rows (the “head” of the DataFrame).\n.info() shows information on each of the columns, such as the data type and number of missing values.\n.shape returns the number of rows and columns of the DataFrame.\n.describe() calculates a few summary statistics for each column.\n\n.values: A two-dimensional NumPy array of values.\n.columns: An index of columns: the column names.\n.index: An index for the rows: either row numbers or row names.","metadata":{},"id":"6fad679d","cell_type":"markdown"},{"source":"_Add your notes here_","metadata":{},"id":"e9a448e0","cell_type":"markdown"},{"source":"# creating a new collum \nhomelessness[\"name_new\"] = homelessness[\"something\"] + homelessness[\"another\"]\n#sort values decending\nhomelessness_ind = homelessness.sort_values(\"individuals\", ascending = False)\n\n#filer by a whole lode of names\n# The Mojave Desert states\ncanu = [\"California\", \"Arizona\", \"Nevada\", \"Utah\"]\n# Filter for rows in the Mojave Desert states\nmojave_homelessness = homelessness[homelessness[\"state\"].isin(canu)]\n\n# Print the mean of weekly_sales do the same only with the other names:\nprint(sales[\"weekly_sales\"].mean())\n\n>>> s = pd.Series([1, 2, 3])\n>>> s.describe()\ncount    3.0\nmean     2.0\nstd      1.0\nmin      1.0\n25%      1.5\n50%      2.0\n75%      2.5\nmax      3.0\n\n>>> s = pd.Series(['a', 'a', 'b', 'c'])\n>>> s.describe()\ncount     4\nunique    3\ntop       a\nfreq      2\ndtype: object\n\n# Drop duplicate store/type combinations\nstore_types = sales.drop_duplicates([\"store\",\"type\"])\nprint(store_types.head())\n\n# Subset the rows where is_holiday is True and drop duplicate dates\nholiday_dates = sales[sales[\"is_holiday\"]].drop_duplicates(subset = \"date\")\n\n#group by multiple collums and multiple use multiple statistics thinks\nunemp_fuel_stats = sales.groupby(\"type\")[[\"unemployment\", \"fuel_price_usd_per_l\"]].agg([np.min, np.max, np.mean, np.median])\n#example avarage weight \navg_weight_by_breed = dog_pack.groupby(\"breed\")[\"weight\"].mean()\n# Get the total number of avocados sold on each date\nnb_sold_by_date = avocados.groupby(\"date\")[\"nb_sold\"].sum()\n\n#pivot_table does the same thing:\nsales.pivot_table(values=\"unemployment\", index=\"type\", aggfunc=(np.min, np.max, np.mean, np.median))\n\nsales.pivot_table(values=\"weekly_sales\", index=\"type\", columns=\"is_holiday\",aggfunc=np.median, fill_value=0, margins=True)\n\n# Pivot avg_temp_c by country and city vs year\ntemp_by_country_city_vs_year = temperatures.pivot_table(\n    values=\"avg_temp_c\",\n    index=[\"country\", \"city\"],\n    columns=\"year\")\n\n#indexing makes subsetting simpeler, but it is harder to read and isnt tidy data anymore:\n#setting a collumn as the index\ntemperature_ind = temperature.set_index(\"plaats\") #multiple would be [\"paris\",\"lourin\"]\n#to reset an index use reset_index\ntemperature_ind.reset_index() #if you want to drop (drop=True)\n\n#to subset the outer level with a list\ntemperature.loc[[\"paris\",\"lourin\"]]\n\n#to subset multiple innerleves\ntemperature.loc[[(\"paris\", \"summer\"),(\"lourin\",\"winter\")]]\n# Sort temperatures_ind by index values\nprint(temperatures_ind.sort_index())\n\n# Sort temperatures_ind by index values at the city level\nprint(temperatures_ind.sort_index(level = \"city\"))\n\n# Sort temperatures_ind by country then descending city\nprint(temperatures_ind.sort_index(level = [\"country\", \"city\"], ascending = [True, False]))\n\n#slicing list:\n#it is counted with the 0 and the later is not included, so this would give the 2 3 and 4 row\nbreeds[2:5]\n#if you want the first 3 values use:\nbreeds[:3]\n#slicing index\n#slicing the outer index level you first need to sort the data poodle is now included\ndogs_srt.loc[\"Chow Chow\" : \"Poodle\"]\n#slicing inner levels you also need to include the outer levels\ndogs_srt.loc[(\"labrador\", \"Brown\"):(\"schauzer\", \"Grey\")]\n#slicing columns but keeping all rows:\ndogs_srt.loc[:, \"name\":\"height\"]\n#you can also slice rows and collumns at the sime time:\ndogs_srt.loc[(\"labrador\", \"Brown\"):(\"schauzer\", \"Grey\"),\"name\":\"height\"]\n#important example, get data between dates:\ndogs_srt.loc[\"2014-08-25\":\"2016-09-16\"] # you can also do the dates like \"2014\":\"2016\"\n\n#subsetting by row and column:\ndog.iloc[2:5, 1:4]\n\n#pivot tables:\n# Add a year column to temperatures\ntemperatures[\"year\"] = temperatures[\"date\"].dt.year\n\n#calc with pivot table:\n# Get the worldwide mean temp by year\nmean_temp_by_year = temp_by_country_city_vs_year.mean()\n# Filter for the year that had the highest mean temp\nprint(mean_temp_by_year[mean_temp_by_year == mean_temp_by_year.max()])\n# Get the mean temp by city\nmean_temp_by_city = temp_by_country_city_vs_year.mean(axis=\"columns\")\n# Filter for the city that had the lowest mean temp\nprint(mean_temp_by_city[mean_temp_by_city == mean_temp_by_city.min()])\n\n#visualisation:\nimport matplotlib.pyploy as plt\ndog_pack[\"height_cm\"].hist(bins=10 #number of columns in plt\n                           alpha=0.7)#transparency\nplt.show() #you have to put this behind all the plots you make for it to show\n#bar plot\navg_weight_by_breed.plot(kind=\"bar\", title =\"helemaal mooi\")\n#line\ndatasett.plot(x=\"date\",#x argument\n              y=\"weight_kg\",#y argument\n              kind=\"line\",#type of plot\n              rot=45)#rotating angle of label\n#legend for the plt\nplt.legend(\"gewicht\") #if multiple datasets [\"F\",\"M\"]\n\n#missing values\n#show if there are any missing values\ndogs.isna().any() #you can leave the any and it wil show it for the whole\n#count the number of missing values\ndogs.isna().sum()\n#visualize the missing numbers\ndogs.isna().sum().plot(kind=\"bar\")\n#drop missing value\ndogs.dropna()\n#fill missing value\ndogs.fillna(0)\n\n#make a list of dictionaries\navocados_list = [\n    {\"date\": \"2019-11-03\", \"small_sold\": 10376832, \"large_sold\": 7835071},\n    {\"date\": \"2019-11-10\", \"small_sold\": 10717154, \"large_sold\": 8561348},\n]\n#convert it in to dataframe form\navocado = pd.DataFrame(avocados_list)\n\n#make a dictionary of lists you can make it in a dataframe the same way\navacodos_dict_list = {\n    \"date\": [\"2019-11-03\", \"2019-11-10\"],\n    \"small_sold\": [10376832,10717154],\n    \"large_sold\": [7835071, 8561348]\n}\n\nmovie_plots = pd.read_csv(\"C:/Users/woute/Documents/Minor/Assignments/Assignment_2/movie_plots-1.csv\") #open the file from the saved location\n\n#when you have minupulated the data you can save it again as a csv\nnew_dogs.to_csv(\"title.csv\")","metadata":{},"id":"893055c9","cell_type":"code","execution_count":null,"outputs":[]},{"source":"## Explore Datasets\nUse the DataFrames imported in the first cell to explore the data and practice your skills!\n- Print the highest weekly sales for each `department` in the `walmart` DataFrame. Limit your results to the top five departments, in descending order. If you're stuck, try reviewing this [video](https://campus.datacamp.com/courses/data-manipulation-with-pandas/aggregating-dataframes?ex=1).\n- What was the total `nb_sold` of organic avocados in 2017 in the `avocado` DataFrame? If you're stuck, try reviewing this [video](https://campus.datacamp.com/courses/data-manipulation-with-pandas/slicing-and-indexing-dataframes?ex=6).\n- Create a bar plot of the total number of homeless people by region in the `homelessness` DataFrame. Order the bars in descending order. Bonus: create a horizontal bar chart. If you're stuck, try reviewing this [video](https://campus.datacamp.com/courses/data-manipulation-with-pandas/creating-and-visualizing-dataframes?ex=1).\n- Create a line plot with two lines representing the temperatures in Toronto and Rome. Make sure to properly label your plot. Bonus: add a legend for the two lines. If you're stuck, try reviewing this [video](https://campus.datacamp.com/courses/data-manipulation-with-pandas/creating-and-visualizing-dataframes?ex=1).","metadata":{},"id":"c09c5c3a","cell_type":"markdown"}],"metadata":{"language_info":{"name":"python","version":"3.8.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"editor":"DataCamp Workspace"},"nbformat":4,"nbformat_minor":5}