{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01385b60-7fbe-45c5-a62e-425f94247aad",
   "metadata": {},
   "source": [
    "# Species Classification with Metadata and Uncertainty — iNaturalist Project\n",
    "\n",
    "In this notebook, we will build an **image classification Convolutional neural network** for identifying species \n",
    "from the iNaturalist dataset. Our model will combine computer vision with **user-provided metadata** \n",
    "(like animal kingdom and phylum), and output both a prediction and an **uncertainty estimate** to build trust in the \n",
    "computer vision of the app.\n",
    "\n",
    "---\n",
    "\n",
    "## Objectives to improve from simple CNN\n",
    "\n",
    "1. Load and preprocess the iNaturalist dataset.\n",
    "2. Apply **advanced image augmentation** using `albumentations` to increase performance.\n",
    "3. Build a model that combines:\n",
    "    - CNN features from a **pretrained Tensorflow**.\n",
    "    - The database of Inaturalist this includes **images, categories,annotations**.\n",
    "4. Train using **Class-Balanced Loss (CB Loss)** for imbalanced species data.\n",
    "5. Implement **Monte Carlo Dropout** for uncertainty estimation.\n",
    "6. Test predictions with confidence and uncertainty output.\n",
    " \n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e0648d-ad2b-4614-9595-5d22c3ca84ac",
   "metadata": {},
   "source": [
    "## Loading and Preparing Data\n",
    "\n",
    "```python\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Flatten, Activation, Dropout, GlobalAveragePooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers, applications\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\n",
    "from keras import backend as K \n",
    "import albumentations as A\n",
    "from albumentations.core.composition import OneOf\n",
    "from albumentations.pytorch import ToTensorV2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf1f8d7-99c9-45cd-93aa-8bb1546d814a",
   "metadata": {},
   "source": [
    "## Example: open the train data from the github from iNaturalist\n",
    "ann_file = '../input/inaturalist-2019-fgvc6/train2019.json'\n",
    "with open(ann_file) as data_file:\n",
    "        train_anns = json.load(data_file)\n",
    "\n",
    "train_anns_df = pd.DataFrame(train_anns['annotations'])[['image_id','category_id']]\n",
    "train_img_df = pd.DataFrame(train_anns['images'])[['id', 'file_name']].rename(columns={'id':'image_id'})\n",
    "train_cat_df = pd.DataFrame(train_anns['categories']) #also add the category's in the training data, so later the metadata can be added\n",
    "df_train_file_cat = pd.merge(train_img_df, train_anns_df, train_cat_df, on='image_id')\n",
    "df_train_file_cat['category_id']=df_train_file_cat['category_id'].astype(str)\n",
    "df_train_file_cat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba2d511-7d07-47aa-83b7-d0a77058f7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of images for category_id = 400\n",
    "img_names = df_train_file_cat[df_train_file_cat['category_id']=='400']['file_name'][:30]\n",
    "\n",
    "plt.figure(figsize=[15,15])\n",
    "i = 1\n",
    "for img_name in img_names:\n",
    "    img = cv2.imread(\"../input/inaturalist-2019-fgvc6/train_val2019/%s\" % img_name)[...,[2, 1, 0]]\n",
    "    plt.subplot(6, 5, i)\n",
    "    plt.imshow(img)\n",
    "    i += 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aca9f13-58b3-409b-9b98-b5fe408448ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Example: open the validation data from the github from iNaturalist\n",
    "valid_ann_file = '../input/inaturalist-2019-fgvc6/val2019.json'\n",
    "with open(valid_ann_file) as data_file:\n",
    "        valid_anns = json.load(data_file)\n",
    "    \n",
    "valid_anns_df = pd.DataFrame(valid_anns['annotations'])[['image_id','category_id']]\n",
    "valid_anns_df.head()\n",
    "valid_img_df = pd.DataFrame(valid_anns['images'])[['id', 'file_name']].rename(columns={'id':'image_id'})\n",
    "valid_img_df.head()\n",
    "valid_cat_df = pd.DataFrame(train_anns['categories']) #also add the category's in the training data, so later the metadata can be added\n",
    "valid_cat_df.head()\n",
    "df_valid_file_cat = pd.merge(valid_img_df, valid_anns_df, valid_cat_df, on='image_id')\n",
    "df_valid_file_cat['category_id']=df_valid_file_cat['category_id'].astype(str)\n",
    "df_valid_file_cat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92181d49-61a4-4341-b306-b654ca903b11",
   "metadata": {},
   "source": [
    "## augmentation\n",
    "Data augmentation is a technique used in machine learning — especially in computer vision — to artificially increase the size and variety of a training dataset by creating modified versions of existing images.\n",
    "\n",
    "This helps the model generalize better and become less sensitive to specific positions, lighting, angles, or distortions in the input data.\n",
    "\n",
    "Typical image augmentations include:\n",
    "\n",
    "-Resizing & Cropping\n",
    "-Flipping and Rotating\n",
    "-Brightness and Contrast Adjustments\n",
    "-Shifting, Scaling, and Zooming\n",
    "-Noise, Blurring, and Distortion\n",
    "\n",
    "By teaching the model to handle these variations, augmentation improves its ability to recognize patterns on new, unseen images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72234f10-321b-46ec-8083-3dcdf4c725b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Apply advanced image augmentation like flipping images, zooming and shifting\n",
    "%%time\n",
    "# Custom Albumentations transform for EfficientNet preprocessing\n",
    "class EfficientNetPreprocess(A.ImageOnlyTransform):\n",
    "    def __init__(self, always_apply=True, p=1.0):\n",
    "        super().__init__(always_apply, p)\n",
    "\n",
    "    def apply(self, image, **params):\n",
    "        return preprocess_input(image)\n",
    "\n",
    "# Training transform\n",
    "train_transform = A.Compose([\n",
    "    A.RandomResizedCrop(300, 300, scale=(0.8, 1.0), p=1.0),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.RandomBrightnessContrast(p=0.3),\n",
    "    A.ShiftScaleRotate(shift_limit=0.2, scale_limit=0.2, rotate_limit=20, p=0.5),\n",
    "    EfficientNetPreprocess(),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "# Validation transform\n",
    "valid_transform = A.Compose([\n",
    "    A.Resize(300, 300),\n",
    "    EfficientNetPreprocess(),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "# Custom Data Generator\n",
    "class AlbumentationsDataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, dataframe, directory, transform, batch_size=32, shuffle=True):\n",
    "        self.dataframe = dataframe.reset_index(drop=True)\n",
    "        self.directory = directory\n",
    "        self.transform = transform\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.indices = np.arange(len(self.dataframe))\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.dataframe) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        batch_indices = self.indices[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        batch = [self.dataframe.iloc[i] for i in batch_indices]\n",
    "        return self.__data_generation(batch)\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "\n",
    "    def __data_generation(self, batch):\n",
    "        X = []\n",
    "        y = []\n",
    "        for record in batch:\n",
    "            image_path = os.path.join(self.directory, record[\"file_name\"])\n",
    "            image = cv2.imread(image_path)\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            augmented = self.transform(image=image)\n",
    "            X.append(augmented['image'].numpy())\n",
    "            y.append(record[\"category_id\"])\n",
    "        \n",
    "        X = np.array(X)\n",
    "        y = tf.keras.utils.to_categorical(y, num_classes=self.dataframe['category_id'].nunique())\n",
    "        return X, y\n",
    "\n",
    "# Create generators\n",
    "train_generator = AlbumentationsDataGenerator(\n",
    "    dataframe=df_train_file_cat,\n",
    "    directory=\"../input/inaturalist-2019-fgvc6/train_val2019\",\n",
    "    transform=train_transform,\n",
    "    batch_size=32,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "valid_generator = AlbumentationsDataGenerator(\n",
    "    dataframe=df_valid_file_cat,\n",
    "    directory=\"../input/inaturalist-2019-fgvc6/train_val2019\",\n",
    "    transform=valid_transform,\n",
    "    batch_size=32,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59011715-93e2-4cb5-be6d-7a64d333851f",
   "metadata": {},
   "source": [
    "## training with model\n",
    "EfficientNetB3 is part of the EfficientNet family a series of convolutional neural networks designed to balance accuracy and efficiency.\n",
    "It’s a great choice because:\n",
    "\n",
    "Pretrained on ImageNet — it has already learned rich visual features from millions of images.\n",
    "Optimized Scaling — EfficientNet scales width, depth, and resolution in a balanced way, so it can handle complex images without wasting resources.\n",
    "\n",
    "Lightweight but Powerful — compared to older models like ResNet or VGG, EfficientNetB3 reaches higher accuracy while using fewer parameters and less computation.\n",
    "\n",
    "Transfer Learning Friendly — you can fine-tune it easily for your own dataset, even with limited labeled data.\n",
    "\n",
    "This makes EfficientNetB3 ideal for modern computer vision tasks when you want a model that is both fast and accurate.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82715f0-1453-417c-a6b0-5128b1bf5a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EfficientNetB3(weights='imagenet', include_top=False, input_shape=(img_size, img_size, 3))\n",
    "model.trainable = False\n",
    "\n",
    "#Adding custom layers \n",
    "x = model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(1024, activation=\"relu\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(nb_classes, activation=\"softmax\")(x)\n",
    "model_final = Model(input = model.input, output = predictions)\n",
    "\n",
    "model_final.compile(optimizers.rmsprop(lr=0.0001, decay=1e-6),loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
